{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c07ea8",
   "metadata": {},
   "source": [
    "# Vehicle counting (YOLOv8 + ByteTrack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13900d34",
   "metadata": {},
   "source": [
    "<h3>Team members:</h3>\n",
    "<ul>\n",
    "    <li>Milad Goudarzi:   10765491</li>\n",
    "    <li>Bita Rahmat Zadeh: 10758773</li>\n",
    "    <li>Kiarash Rezaei:   10809307</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766e267",
   "metadata": {},
   "source": [
    "<h4><b style=\"color:red\">Attention:</b> This is the procedure that is carried out by our team and you <span style=\"color:red\">do not</span> need to follow it. We have put it here as a proof that every step is done by us. Just head to <a href=\"#simple_setup\">\"(Simply) set up the environment\"</a> step .<br/></h4>\n",
    "\n",
    "## <span style=\"font-size:13px\">(Hardly) </span>Set up the environment from scratch\n",
    "Install the package using below steps according to this link https://github.com/ifzhang/ByteTrack :<br/>\n",
    "### 1. Installing ByteTrack\n",
    "`git clone https://github.com/ifzhang/ByteTrack.git` <br/>\n",
    "`cd ByteTrack` <br/>\n",
    "`pip3 install -r requirements.txt` <br/>\n",
    "`python3 setup.py develop` <br/>\n",
    "### 2. Installing pycocotools\n",
    "Just run this command:\n",
    "`conda install -c conda-forge pycocotools`\n",
    "### 3. Installing cython_bbox\n",
    "We also need to install cython_bbox which cannot be installed using `pip` directly. We need to download the cython_bbox package from https://pypi.org/project/cython-bbox/ and then edit the setup.py:<br/>\n",
    "Open cython_bbox folder and find setup.py. Change line 31 in the setup.py from `extra_compile_args=['-Wno-cpp']`, to `extra_compile_args = {'gcc': ['/Qstd=c99']}`. After changing it, go to '.\\cython_bbox-0.1.3\\src' and edit the cython_bbox.pyx file. In cython_bbox.pyx line 12 change `DTYPE = np.float` to `DTYPE = np.float64`. After that, from the command line `cd` to the setup.py directory and run `pip install -e .` (include the dot) <br/>\n",
    "<hr/>\n",
    "\n",
    "### We also need to modify ByteTrack a little\n",
    "We need to change np.float to np.float64 in the following python scripts: \n",
    "<ul><li>jpnotebook\\bytetrack\\yolox\\tracker\\byte_tracker.py: line 18</li>\n",
    "<li>jpnotebook\\bytetrack\\yolox\\tracker\\matching.py (many cases, correct all of them) </li></ul>\n",
    "\n",
    "<h3> Note </h3> <br/>\n",
    "If you face the dead kernel issue due to libiomp5md.dll file in \"path_to_anaconda_envs\\your_env_name\\Library\\bin\\libiomp5md.dll\"\n",
    "directory, you can simply resolve it by deleting that file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128529b5",
   "metadata": {},
   "source": [
    "<a id=\"simple_setup\"></a>\n",
    "## <span style=\"color:green\"> (Simply) Set up the environment</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c25d4",
   "metadata": {},
   "source": [
    "0. You might need to update your Microsoft Visual C++ to version 14.0 or higher. But you might already have it. So just skip this step for now. <br/>\n",
    "1. Preferably install <a href=\"https://www.anaconda.com/download\"> anaconda </a> (or any other virtual environment platform).\n",
    "2. Open anaconda prompt and change your directory to the folder containing \"counting_vehicles.yml\" by `cd path\\to\\theFolder` and simply run this `conda env create -f counting_vehicles.yml`.\n",
    "3. Activate your virtual environment by running `conda activate object_tracking`.\n",
    "4. Open this notebook from the activated virtual environment.\n",
    "5. Run the cell below (ignore the dead kernel message afterwards as it is intentional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62993fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashkan\\Downloads\\03Vehicle_counting_Goudarzi_RahmatZadeh_Rezaei\\cython_bbox-0.1.3\n"
     ]
    }
   ],
   "source": [
    "%cd cython_bbox-0.1.3\n",
    "%pip install -e .\n",
    "%cd ..\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfa8e0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style=\"color:green\"> 6. Done! </b><br/>\n",
    "<span style=\"color:red\">Note: </span> If you encountered with MS. Visual C++ error, you can use the `vs_BuildTools.exe` from project files to update to the required version (14 or higher). You need to install/update only the V.S. Build tools component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640be13",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c06d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\\ByteTrack\")\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from math import sqrt\n",
    "from deep_sort_pytorch_2nd.utils.parser import get_config\n",
    "from deep_sort_pytorch_2nd.deep_sort import DeepSort\n",
    "import torch\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "\n",
    "# YOLO with less parameters\n",
    "#model = YOLO(model='yolov8n.pt')\n",
    "\n",
    "# YOLO with large number of parameters\n",
    "model = YOLO('YOLOv8x.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df1c17d",
   "metadata": {},
   "source": [
    "# PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9774c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYTETrackerArgs:\n",
    "    def __init__(self, track_thresh, track_buffer, mot20, match_thresh, \\\n",
    "                aspect_ratio_thresh, min_box_area):\n",
    "        self.track_thresh        = track_thresh\n",
    "        self.track_buffer        = track_buffer\n",
    "        self.mot20               = mot20\n",
    "        self.match_thresh        = match_thresh\n",
    "        self.aspect_ratio_thresh = aspect_ratio_thresh\n",
    "        self.min_box_area        = min_box_area\n",
    "\n",
    "\n",
    "def countVehicles(video_path, output_file_name, vertical, roi_xxyy=(0,0,0,0)):\n",
    "    \n",
    "    assert type(video_path)       == str, \"video_path argument should be string\"\n",
    "    assert type(output_file_name) == str, \"output_file_name argument should be string\"\n",
    "    assert type(vertical)         == bool, \"vertical argument should be boolean\"\n",
    "    \n",
    "    args = BYTETrackerArgs(track_thresh = 0.25,\n",
    "                           track_buffer = 30,\n",
    "                           mot20 = False,\n",
    "                           match_thresh = 0.8,\n",
    "                           aspect_ratio_thresh = 3.0,\n",
    "                           min_box_area = 1.0)\n",
    "    \n",
    "    obj_tracker = BYTETracker(args)\n",
    "    \n",
    "    checkpoint_path = r'deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7'\n",
    "\n",
    "    vid     = cv2.VideoCapture(video_path) \n",
    "    counter = 0\n",
    "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "    writer= cv2.VideoWriter(str(output_file_name), cv2.VideoWriter_fourcc(*'DIVX'), fps, (1067,600))\n",
    "\n",
    "    ids                  = []\n",
    "    already_tested_ids   = []\n",
    "    too_close_tracks_ids = []\n",
    "    \n",
    "    maximum_n = 0 # to keep track of maximum height of counted vehicles in each row, so we can go to next row\n",
    "                  # when we reached end of the frame\n",
    "    while True:\n",
    "        ret, frame    = vid.read()\n",
    "\n",
    "        if ret:\n",
    "            frame         = cv2.resize(frame, (1067,600)) # maintaining 16:9 ratio\n",
    "            height, width = frame.shape[:2]\n",
    "            \n",
    "            # if cars are moving horizontally and user wants to use the default ROI parameters\n",
    "            if (not vertical) and roi_xxyy == (0,0,0,0):\n",
    "                x_starting_point = round(width/5)\n",
    "                x_ending_point   = round(4*width/5)\n",
    "                y_starting_point = round(height/2) + 50\n",
    "                y_ending_point   = round(height/2) + 250\n",
    "            \n",
    "            # if cars are moving vertically and user wants to use the default ROI parameters\n",
    "            elif (vertical) and roi_xxyy == (0,0,0,0):\n",
    "                x_starting_point = 0                #round(width/3)\n",
    "                x_ending_point   = round(3*width/4)\n",
    "                y_starting_point = round(height/2)\n",
    "                y_ending_point   = height           #round(height/2) + 100\n",
    "                \n",
    "            # if user wants to use the his own ROI parameters\n",
    "            else:\n",
    "                a, b, c, d = roi_xxyy\n",
    "                assert type(a) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                assert type(b) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                assert type(c) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                assert type(d) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                \n",
    "                x_starting_point = a\n",
    "                x_ending_point   = b\n",
    "                y_starting_point = c\n",
    "                y_ending_point   = d\n",
    "\n",
    "                \n",
    "            \n",
    "            if not vertical:\n",
    "                areaLine1   = x_starting_point + int((x_ending_point - x_starting_point)/2) - 15\n",
    "                areaLine2   = x_starting_point + int((x_ending_point - x_starting_point)/2) + 15\n",
    "            else:\n",
    "                areaLine1   = y_ending_point - 150\n",
    "                areaLine2   = y_ending_point - 100\n",
    "\n",
    "            # apply adaptive histogram equalization (AHE) in order to increase the contrast in our region of interest.\n",
    "            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
    "\n",
    "            R, G, B = cv2.split(frame[y_starting_point:y_ending_point, x_starting_point:x_ending_point]) # we don't need to\n",
    "                                                                                                         # apply AHE \n",
    "                                                                                                         # to the whole\n",
    "                                                                                                         # frame\n",
    "\n",
    "            cl1 = clahe.apply(R)\n",
    "            cl2 = clahe.apply(G)\n",
    "            cl3 = clahe.apply(B)\n",
    "\n",
    "            orig_frame       = frame.copy() # we take a copy of our original frame before loosing it.\n",
    "            frame            = cv2.merge((cl1, cl2, cl3))\n",
    "            frame_h, frame_w = frame.shape[:2]\n",
    "            frame_size       = np.array([frame_h, frame_w])\n",
    "            orig_frame[y_starting_point:y_ending_point, x_starting_point:x_ending_point] = frame # we replace the region of\n",
    "                                                                                                 # interest with\n",
    "                                                                                                 # the enhanced version of\n",
    "                                                                                                 # it.\n",
    "           \n",
    "            res    = model.predict(frame) # we do the prediction only on the ROI. and not the whole frame.\n",
    "    #         res    = model.predict(frame)\n",
    "            xyxys  = []\n",
    "            confss = []\n",
    "            oids   = []\n",
    "\n",
    "            for result in res:\n",
    "                for box, r in zip(result.boxes, result.boxes.data):\n",
    "                    x, y, w, h = box.xywh[0]\n",
    "                    # we add x_starting_point and y_starting_point to x and y coordinate because we shrinked the frame earlier\n",
    "                    x1, y1, x2, y2 = int(x) + x_starting_point - int(w/2), int(y) + y_starting_point - int(h/2),\\\n",
    "                                    int(x) + x_starting_point + int(w/2), int(y) + y_starting_point + int(h/2)           \n",
    "\n",
    "                    # if class of the detected object is not vehicle then discard it\n",
    "                    if r[-1] > 0 and r[-1] < 8:\n",
    "                        xyxys.append([x1, y1, x2, y2, r[-2]]) # xyxy and score\n",
    "                    confss.append(r[-2])\n",
    "                    oids.append(r[-1]) # class of the detected object\n",
    "\n",
    "\n",
    "            if len(xyxys) > 0:\n",
    "                tracks = obj_tracker.update(np.array(xyxys), frame_size, frame_size)\n",
    "            else:\n",
    "                tracks = np.array([])\n",
    "            if not vertical:\n",
    "                # areaLine1\n",
    "                cv2.line(orig_frame, (areaLine1, y_starting_point), (areaLine1,y_ending_point), (0,0,255), 2)\n",
    "                # areaLine2\n",
    "                cv2.line(orig_frame, (areaLine2, y_starting_point), (areaLine2,y_ending_point), (0,0,255), 2)\n",
    "            else:\n",
    "                # areaLine1\n",
    "                cv2.line(orig_frame, (x_starting_point, areaLine1), (x_ending_point,areaLine1), (0,0,255), 2)\n",
    "                # areaLine2\n",
    "                cv2.line(orig_frame, (x_starting_point, areaLine2), (x_ending_point,areaLine2), (0,0,255), 2)\n",
    "\n",
    "            for track in tracks:\n",
    "                \n",
    "                cv2.putText(orig_frame, str(track.track_id), (int(track.tlbr[0]), int(track.tlbr[1])),cv2.FONT_HERSHEY_SIMPLEX,0.5, [255, 255, 0], thickness=1, lineType=cv2.LINE_AA)\n",
    "                if not vertical:\n",
    "                    conditions = ((track.tlbr[0] > areaLine1 and track.tlbr[0]< areaLine2) and # upper left corner of the bbox should be in the area\n",
    "                                    track.track_id not in ids and\n",
    "                                    track.score > 0.6)\n",
    "                else:\n",
    "                    conditions = ((track.tlbr[1] > areaLine1 and track.tlbr[1]< areaLine2) and # upper left corner of the bbox should be in the area\n",
    "                                    track.track_id not in ids and\n",
    "                                    track.score > 0.6)\n",
    "\n",
    "                if (conditions):\n",
    "\n",
    "                    cv2.putText(orig_frame, str(track.track_id), (int(track.tlbr[0]), int(track.tlbr[1])),cv2.FONT_HERSHEY_SIMPLEX,0.8, [0, 255, 0], thickness=2, lineType=cv2.LINE_AA)                    \n",
    "                    ids.append(track.track_id)\n",
    "\n",
    "\n",
    "            # Showing the counter on top left side of the frame\n",
    "            counter = len(ids)\n",
    "            cv2.putText(orig_frame, \"Count: \" + str(counter), (50,50), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1, color=(255, 0, 0))\n",
    "            \n",
    "            n = 20   # starting row for displaying the counted vehicle image in the original frame\n",
    "            m = 250  # starting column for displaying the counted vehicle image in the original frame\n",
    "            for track in tracks:\n",
    "                if (track.track_id in ids):\n",
    "                    cv2.rectangle(orig_frame, (int(track.tlbr[0]),int(track.tlbr[1])), (int(track.tlbr[2]),int(track.tlbr[3])), (0,255,0), 2)\n",
    "                    cv2.rectangle(orig_frame, (m, n), (m+int(track.tlwh[2]), n+int(track.tlwh[3])), (0,255,0), 2)\n",
    "                    try:\n",
    "                        orig_frame[n:n+int(track.tlwh[3]), m:m+int(track.tlwh[2])] = \\\n",
    "                            orig_frame[int(track.tlwh[1]):int(track.tlwh[1])+int(track.tlwh[3]), int(track.tlwh[0]):int(track.tlwh[0])+int(track.tlwh[2])]\n",
    "                        m += int(track.tlwh[2])+5\n",
    "                    except:\n",
    "                        print(\"Error!\")\n",
    "            \n",
    "            # drawing our RoI (Region of Interest)\n",
    "            cv2.rectangle(orig_frame, (x_starting_point, y_starting_point), (x_ending_point,y_ending_point), (255,255,0), 1)\n",
    "\n",
    "            writer.write(orig_frame)\n",
    "            cv2.imshow('frame', orig_frame)        \n",
    "\n",
    "            # press esc for quitting the video\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    vid.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78aea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 1 person, 12 cars, 858.7ms\n",
      "Speed: 9.4ms preprocess, 858.7ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 845.3ms\n",
      "Speed: 6.0ms preprocess, 845.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 778.5ms\n",
      "Speed: 5.4ms preprocess, 778.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 763.0ms\n",
      "Speed: 15.5ms preprocess, 763.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 14 cars, 758.1ms\n",
      "Speed: 0.0ms preprocess, 758.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 bench, 762.9ms\n",
      "Speed: 0.0ms preprocess, 762.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 746.4ms\n",
      "Speed: 9.2ms preprocess, 746.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 717.7ms\n",
      "Speed: 0.0ms preprocess, 717.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 708.4ms\n",
      "Speed: 0.0ms preprocess, 708.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 732.8ms\n",
      "Speed: 0.0ms preprocess, 732.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 718.0ms\n",
      "Speed: 0.0ms preprocess, 718.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 708.4ms\n",
      "Speed: 0.0ms preprocess, 708.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 14 cars, 723.8ms\n",
      "Speed: 0.0ms preprocess, 723.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 14 cars, 716.2ms\n",
      "Speed: 0.0ms preprocess, 716.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 707.2ms\n",
      "Speed: 0.0ms preprocess, 707.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 718.1ms\n",
      "Speed: 0.0ms preprocess, 718.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 715.9ms\n",
      "Speed: 0.0ms preprocess, 715.9ms inference, 10.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 traffic light, 709.1ms\n",
      "Speed: 3.0ms preprocess, 709.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 709.5ms\n",
      "Speed: 1.3ms preprocess, 709.5ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 704.0ms\n",
      "Speed: 6.5ms preprocess, 704.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 709.5ms\n",
      "Speed: 0.0ms preprocess, 709.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 703.7ms\n",
      "Speed: 0.0ms preprocess, 703.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 719.9ms\n",
      "Speed: 4.2ms preprocess, 719.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 724.8ms\n",
      "Speed: 0.0ms preprocess, 724.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 718.7ms\n",
      "Speed: 0.0ms preprocess, 718.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 710.2ms\n",
      "Speed: 0.0ms preprocess, 710.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 710.1ms\n",
      "Speed: 0.0ms preprocess, 710.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 715.6ms\n",
      "Speed: 0.0ms preprocess, 715.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 702.3ms\n",
      "Speed: 9.5ms preprocess, 702.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 traffic light, 708.7ms\n",
      "Speed: 0.0ms preprocess, 708.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 traffic light, 709.5ms\n",
      "Speed: 3.8ms preprocess, 709.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 710.4ms\n",
      "Speed: 0.0ms preprocess, 710.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 13 cars, 706.7ms\n",
      "Speed: 0.0ms preprocess, 706.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 motorcycle, 708.8ms\n",
      "Speed: 0.0ms preprocess, 708.8ms inference, 11.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 10 cars, 1 traffic light, 710.1ms\n",
      "Speed: 0.0ms preprocess, 710.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 711.2ms\n",
      "Speed: 0.0ms preprocess, 711.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 702.6ms\n",
      "Speed: 3.9ms preprocess, 702.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 710.5ms\n",
      "Speed: 0.0ms preprocess, 710.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 traffic light, 715.9ms\n",
      "Speed: 0.0ms preprocess, 715.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 11 cars, 1 traffic light, 725.6ms\n",
      "Speed: 0.0ms preprocess, 725.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 11 cars, 1 traffic light, 727.2ms\n",
      "Speed: 0.0ms preprocess, 727.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 12 cars, 1 traffic light, 711.8ms\n",
      "Speed: 0.0ms preprocess, 711.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 12 cars, 1 traffic light, 698.1ms\n",
      "Speed: 5.3ms preprocess, 698.1ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 13 cars, 1 traffic light, 707.3ms\n",
      "Speed: 1.0ms preprocess, 707.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 12 cars, 1 traffic light, 707.3ms\n",
      "Speed: 0.0ms preprocess, 707.3ms inference, 10.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 704.4ms\n",
      "Speed: 0.0ms preprocess, 704.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 708.6ms\n",
      "Speed: 2.1ms preprocess, 708.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 705.3ms\n",
      "Speed: 2.5ms preprocess, 705.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 1 bicycle, 11 cars, 726.7ms\n",
      "Speed: 8.0ms preprocess, 726.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 1 bicycle, 11 cars, 705.2ms\n",
      "Speed: 1.6ms preprocess, 705.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 1 bicycle, 11 cars, 710.9ms\n",
      "Speed: 0.0ms preprocess, 710.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 1 bicycle, 10 cars, 702.0ms\n",
      "Speed: 8.7ms preprocess, 702.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 10 cars, 726.0ms\n",
      "Speed: 0.0ms preprocess, 726.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 716.1ms\n",
      "Speed: 0.0ms preprocess, 716.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 traffic light, 709.1ms\n",
      "Speed: 0.9ms preprocess, 709.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 708.5ms\n",
      "Speed: 0.0ms preprocess, 708.5ms inference, 14.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 709.4ms\n",
      "Speed: 8.1ms preprocess, 709.4ms inference, 8.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 708.3ms\n",
      "Speed: 0.0ms preprocess, 708.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 13 cars, 1 traffic light, 711.8ms\n",
      "Speed: 0.0ms preprocess, 711.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 716.9ms\n",
      "Speed: 8.5ms preprocess, 716.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 13 cars, 1 traffic light, 708.9ms\n",
      "Speed: 7.2ms preprocess, 708.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 720.8ms\n",
      "Speed: 0.0ms preprocess, 720.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 13 cars, 1 traffic light, 708.2ms\n",
      "Speed: 0.0ms preprocess, 708.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 704.8ms\n",
      "Speed: 0.0ms preprocess, 704.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 10 cars, 1 traffic light, 705.2ms\n",
      "Speed: 0.0ms preprocess, 705.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 traffic light, 725.1ms\n",
      "Speed: 0.0ms preprocess, 725.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 traffic light, 703.5ms\n",
      "Speed: 8.1ms preprocess, 703.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 10 cars, 1 traffic light, 714.6ms\n",
      "Speed: 5.0ms preprocess, 714.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 traffic light, 716.5ms\n",
      "Speed: 0.0ms preprocess, 716.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 traffic light, 694.9ms\n",
      "Speed: 9.2ms preprocess, 694.9ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 702.1ms\n",
      "Speed: 0.0ms preprocess, 702.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 1 traffic light, 701.7ms\n",
      "Speed: 10.0ms preprocess, 701.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 12 cars, 1 traffic light, 706.0ms\n",
      "Speed: 5.5ms preprocess, 706.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 traffic light, 702.7ms\n",
      "Speed: 0.0ms preprocess, 702.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 10 cars, 1 traffic light, 706.9ms\n",
      "Speed: 1.5ms preprocess, 706.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 15 cars, 708.5ms\n",
      "Speed: 0.0ms preprocess, 708.5ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 14 cars, 1 traffic light, 703.2ms\n",
      "Speed: 0.0ms preprocess, 703.2ms inference, 16.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 712.3ms\n",
      "Speed: 4.6ms preprocess, 712.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 709.0ms\n",
      "Speed: 0.0ms preprocess, 709.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 707.8ms\n",
      "Speed: 1.5ms preprocess, 707.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 713.1ms\n",
      "Speed: 1.1ms preprocess, 713.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 719.8ms\n",
      "Speed: 0.0ms preprocess, 719.8ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 741.5ms\n",
      "Speed: 0.0ms preprocess, 741.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 709.1ms\n",
      "Speed: 4.5ms preprocess, 709.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 727.8ms\n",
      "Speed: 0.0ms preprocess, 727.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 707.1ms\n",
      "Speed: 5.9ms preprocess, 707.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 727.2ms\n",
      "Speed: 2.7ms preprocess, 727.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 12 cars, 726.4ms\n",
      "Speed: 2.1ms preprocess, 726.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 2 bicycles, 12 cars, 1 traffic light, 729.5ms\n",
      "Speed: 0.0ms preprocess, 729.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 719.6ms\n",
      "Speed: 0.0ms preprocess, 719.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 718.5ms\n",
      "Speed: 0.0ms preprocess, 718.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 722.6ms\n",
      "Speed: 0.0ms preprocess, 722.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 bench, 703.4ms\n",
      "Speed: 8.0ms preprocess, 703.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 701.5ms\n",
      "Speed: 2.7ms preprocess, 701.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 bench, 716.8ms\n",
      "Speed: 0.0ms preprocess, 716.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 706.1ms\n",
      "Speed: 0.0ms preprocess, 706.1ms inference, 15.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 bench, 695.2ms\n",
      "Speed: 2.0ms preprocess, 695.2ms inference, 15.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 721.2ms\n",
      "Speed: 0.0ms preprocess, 721.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 traffic light, 702.9ms\n",
      "Speed: 0.0ms preprocess, 702.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 709.6ms\n",
      "Speed: 8.0ms preprocess, 709.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 712.0ms\n",
      "Speed: 0.0ms preprocess, 712.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 716.0ms\n",
      "Speed: 0.0ms preprocess, 716.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 708.6ms\n",
      "Speed: 9.2ms preprocess, 708.6ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 734.8ms\n",
      "Speed: 7.5ms preprocess, 734.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 1 bench, 716.0ms\n",
      "Speed: 7.1ms preprocess, 716.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 traffic light, 1 bench, 719.5ms\n",
      "Speed: 0.7ms preprocess, 719.5ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 736.3ms\n",
      "Speed: 0.0ms preprocess, 736.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 730.0ms\n",
      "Speed: 0.0ms preprocess, 730.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 711.0ms\n",
      "Speed: 7.0ms preprocess, 711.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 1 bench, 723.0ms\n",
      "Speed: 0.0ms preprocess, 723.0ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 1 bench, 717.3ms\n",
      "Speed: 0.0ms preprocess, 717.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 726.5ms\n",
      "Speed: 0.0ms preprocess, 726.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 726.3ms\n",
      "Speed: 0.0ms preprocess, 726.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 728.8ms\n",
      "Speed: 0.0ms preprocess, 728.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 1 bench, 734.6ms\n",
      "Speed: 0.0ms preprocess, 734.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 719.2ms\n",
      "Speed: 5.1ms preprocess, 719.2ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 730.0ms\n",
      "Speed: 4.8ms preprocess, 730.0ms inference, 4.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 715.2ms\n",
      "Speed: 0.0ms preprocess, 715.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 705.6ms\n",
      "Speed: 0.0ms preprocess, 705.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 722.4ms\n",
      "Speed: 0.0ms preprocess, 722.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 728.7ms\n",
      "Speed: 0.0ms preprocess, 728.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 14 cars, 1 traffic light, 721.5ms\n",
      "Speed: 1.0ms preprocess, 721.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 707.8ms\n",
      "Speed: 1.5ms preprocess, 707.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 14 cars, 1 traffic light, 708.5ms\n",
      "Speed: 1.4ms preprocess, 708.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 732.4ms\n",
      "Speed: 2.5ms preprocess, 732.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 726.6ms\n",
      "Speed: 1.8ms preprocess, 726.6ms inference, 6.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 710.3ms\n",
      "Speed: 1.6ms preprocess, 710.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 706.5ms\n",
      "Speed: 2.3ms preprocess, 706.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 731.9ms\n",
      "Speed: 0.0ms preprocess, 731.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 718.5ms\n",
      "Speed: 0.0ms preprocess, 718.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 711.6ms\n",
      "Speed: 0.0ms preprocess, 711.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 708.5ms\n",
      "Speed: 8.0ms preprocess, 708.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 716.3ms\n",
      "Speed: 1.7ms preprocess, 716.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 738.1ms\n",
      "Speed: 0.0ms preprocess, 738.1ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 725.5ms\n",
      "Speed: 0.0ms preprocess, 725.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 734.6ms\n",
      "Speed: 0.0ms preprocess, 734.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 traffic light, 726.4ms\n",
      "Speed: 0.0ms preprocess, 726.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 730.4ms\n",
      "Speed: 2.2ms preprocess, 730.4ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 744.4ms\n",
      "Speed: 0.0ms preprocess, 744.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 722.1ms\n",
      "Speed: 2.8ms preprocess, 722.1ms inference, 9.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 710.5ms\n",
      "Speed: 12.0ms preprocess, 710.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 713.6ms\n",
      "Speed: 0.0ms preprocess, 713.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 724.5ms\n",
      "Speed: 1.3ms preprocess, 724.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 708.7ms\n",
      "Speed: 0.0ms preprocess, 708.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 706.3ms\n",
      "Speed: 0.0ms preprocess, 706.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 712.2ms\n",
      "Speed: 0.0ms preprocess, 712.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 715.0ms\n",
      "Speed: 1.2ms preprocess, 715.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 715.3ms\n",
      "Speed: 0.0ms preprocess, 715.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 704.4ms\n",
      "Speed: 7.0ms preprocess, 704.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 715.5ms\n",
      "Speed: 1.1ms preprocess, 715.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 711.1ms\n",
      "Speed: 0.0ms preprocess, 711.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 717.1ms\n",
      "Speed: 0.0ms preprocess, 717.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 711.2ms\n",
      "Speed: 5.2ms preprocess, 711.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 708.9ms\n",
      "Speed: 0.0ms preprocess, 708.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 717.3ms\n",
      "Speed: 8.0ms preprocess, 717.3ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 727.6ms\n",
      "Speed: 0.0ms preprocess, 727.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 732.5ms\n",
      "Speed: 0.0ms preprocess, 732.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 traffic light, 714.1ms\n",
      "Speed: 0.0ms preprocess, 714.1ms inference, 6.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 712.2ms\n",
      "Speed: 6.5ms preprocess, 712.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 705.2ms\n",
      "Speed: 0.0ms preprocess, 705.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 711.9ms\n",
      "Speed: 0.0ms preprocess, 711.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 711.9ms\n",
      "Speed: 0.0ms preprocess, 711.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 711.4ms\n",
      "Speed: 0.0ms preprocess, 711.4ms inference, 3.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 723.8ms\n",
      "Speed: 0.0ms preprocess, 723.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 714.6ms\n",
      "Speed: 1.9ms preprocess, 714.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 714.4ms\n",
      "Speed: 15.9ms preprocess, 714.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 702.9ms\n",
      "Speed: 0.0ms preprocess, 702.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 711.4ms\n",
      "Speed: 8.0ms preprocess, 711.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 708.4ms\n",
      "Speed: 3.8ms preprocess, 708.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 706.6ms\n",
      "Speed: 0.0ms preprocess, 706.6ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 10 cars, 1 traffic light, 709.6ms\n",
      "Speed: 1.1ms preprocess, 709.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 703.4ms\n",
      "Speed: 6.0ms preprocess, 703.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 711.2ms\n",
      "Speed: 1.8ms preprocess, 711.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 715.7ms\n",
      "Speed: 7.0ms preprocess, 715.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 727.2ms\n",
      "Speed: 6.9ms preprocess, 727.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 697.1ms\n",
      "Speed: 8.0ms preprocess, 697.1ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 704.9ms\n",
      "Speed: 6.5ms preprocess, 704.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 706.7ms\n",
      "Speed: 0.0ms preprocess, 706.7ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 701.7ms\n",
      "Speed: 0.0ms preprocess, 701.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 702.7ms\n",
      "Speed: 2.7ms preprocess, 702.7ms inference, 15.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 703.6ms\n",
      "Speed: 0.0ms preprocess, 703.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 713.5ms\n",
      "Speed: 8.0ms preprocess, 713.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 13 cars, 1 traffic light, 704.6ms\n",
      "Speed: 8.8ms preprocess, 704.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 719.8ms\n",
      "Speed: 0.0ms preprocess, 719.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 693.9ms\n",
      "Speed: 0.0ms preprocess, 693.9ms inference, 16.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 711.3ms\n",
      "Speed: 2.9ms preprocess, 711.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 722.6ms\n",
      "Speed: 0.0ms preprocess, 722.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 717.8ms\n",
      "Speed: 0.0ms preprocess, 717.8ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 704.2ms\n",
      "Speed: 0.0ms preprocess, 704.2ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 696.6ms\n",
      "Speed: 9.0ms preprocess, 696.6ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 11 cars, 1 traffic light, 708.5ms\n",
      "Speed: 1.1ms preprocess, 708.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 12 cars, 1 traffic light, 695.5ms\n",
      "Speed: 0.0ms preprocess, 695.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 726.8ms\n",
      "Speed: 0.0ms preprocess, 726.8ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 714.7ms\n",
      "Speed: 0.0ms preprocess, 714.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 13 cars, 1 traffic light, 706.9ms\n",
      "Speed: 0.0ms preprocess, 706.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 9 cars, 1 traffic light, 711.8ms\n",
      "Speed: 0.0ms preprocess, 711.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 10 cars, 1 traffic light, 721.0ms\n",
      "Speed: 0.0ms preprocess, 721.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 10 cars, 1 traffic light, 708.4ms\n",
      "Speed: 3.5ms preprocess, 708.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 10 cars, 1 traffic light, 708.9ms\n",
      "Speed: 4.0ms preprocess, 708.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 8 cars, 1 traffic light, 715.9ms\n",
      "Speed: 0.0ms preprocess, 715.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 8 cars, 1 motorcycle, 1 traffic light, 709.8ms\n",
      "Speed: 0.0ms preprocess, 709.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 8 cars, 1 motorcycle, 1 traffic light, 721.8ms\n",
      "Speed: 7.5ms preprocess, 721.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 8 cars, 1 motorcycle, 1 traffic light, 705.5ms\n",
      "Speed: 0.0ms preprocess, 705.5ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 9 cars, 1 motorcycle, 1 traffic light, 693.8ms\n",
      "Speed: 1.5ms preprocess, 693.8ms inference, 16.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 7 cars, 1 motorcycle, 1 traffic light, 711.5ms\n",
      "Speed: 7.0ms preprocess, 711.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 8 cars, 1 motorcycle, 1 traffic light, 718.9ms\n",
      "Speed: 1.0ms preprocess, 718.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 9 cars, 1 motorcycle, 1 traffic light, 713.7ms\n",
      "Speed: 0.0ms preprocess, 713.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 9 cars, 1 motorcycle, 1 traffic light, 714.8ms\n",
      "Speed: 0.0ms preprocess, 714.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 motorcycle, 1 traffic light, 716.9ms\n",
      "Speed: 1.2ms preprocess, 716.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 10 cars, 1 motorcycle, 1 traffic light, 1 bench, 713.9ms\n",
      "Speed: 0.0ms preprocess, 713.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 11 cars, 1 motorcycle, 1 traffic light, 727.1ms\n",
      "Speed: 0.0ms preprocess, 727.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 12 cars, 1 motorcycle, 1 traffic light, 706.3ms\n",
      "Speed: 0.0ms preprocess, 706.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 10 cars, 2 motorcycles, 1 traffic light, 704.6ms\n",
      "Speed: 9.4ms preprocess, 704.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 11 cars, 1 motorcycle, 1 traffic light, 710.4ms\n",
      "Speed: 0.0ms preprocess, 710.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 9 cars, 1 motorcycle, 1 traffic light, 714.8ms\n",
      "Speed: 0.0ms preprocess, 714.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 7 cars, 1 traffic light, 723.0ms\n",
      "Speed: 0.0ms preprocess, 723.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 1 person, 1 bicycle, 7 cars, 1 motorcycle, 1 traffic light, 712.0ms\n",
      "Speed: 7.1ms preprocess, 712.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 7 cars, 2 motorcycles, 1 traffic light, 724.1ms\n",
      "Speed: 0.0ms preprocess, 724.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 9 cars, 2 motorcycles, 1 traffic light, 716.7ms\n",
      "Speed: 0.0ms preprocess, 716.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 8 cars, 1 motorcycle, 1 traffic light, 723.0ms\n",
      "Speed: 1.4ms preprocess, 723.0ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 8 cars, 1 motorcycle, 1 traffic light, 711.2ms\n",
      "Speed: 0.0ms preprocess, 711.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 8 cars, 1 traffic light, 701.5ms\n",
      "Speed: 8.1ms preprocess, 701.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 12 cars, 1 traffic light, 1 backpack, 1 handbag, 715.0ms\n",
      "Speed: 2.8ms preprocess, 715.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 12 cars, 1 traffic light, 1 backpack, 1 handbag, 710.3ms\n",
      "Speed: 0.0ms preprocess, 710.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 13 cars, 1 motorcycle, 1 traffic light, 1 backpack, 1 handbag, 714.3ms\n",
      "Speed: 0.0ms preprocess, 714.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 12 cars, 1 traffic light, 1 backpack, 1 handbag, 695.1ms\n",
      "Speed: 8.8ms preprocess, 695.1ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 11 cars, 1 traffic light, 1 backpack, 706.6ms\n",
      "Speed: 0.0ms preprocess, 706.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 14 cars, 1 motorcycle, 1 traffic light, 1 backpack, 1 handbag, 722.7ms\n",
      "Speed: 0.0ms preprocess, 722.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 13 cars, 1 motorcycle, 1 traffic light, 1 backpack, 716.0ms\n",
      "Speed: 0.0ms preprocess, 716.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 13 cars, 1 traffic light, 1 backpack, 708.5ms\n",
      "Speed: 2.0ms preprocess, 708.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 13 cars, 1 motorcycle, 1 traffic light, 1 backpack, 718.7ms\n",
      "Speed: 0.0ms preprocess, 718.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 13 cars, 1 motorcycle, 1 traffic light, 2 backpacks, 716.0ms\n",
      "Speed: 2.8ms preprocess, 716.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 12 cars, 1 motorcycle, 1 traffic light, 1 backpack, 705.4ms\n",
      "Speed: 0.0ms preprocess, 705.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 14 cars, 1 motorcycle, 1 traffic light, 1 backpack, 738.4ms\n",
      "Speed: 0.0ms preprocess, 738.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 14 cars, 1 motorcycle, 1 traffic light, 1 backpack, 712.3ms\n",
      "Speed: 8.1ms preprocess, 712.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 13 cars, 1 motorcycle, 1 traffic light, 1 backpack, 717.0ms\n",
      "Speed: 0.0ms preprocess, 717.0ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 15 cars, 1 motorcycle, 1 traffic light, 1 backpack, 726.2ms\n",
      "Speed: 2.5ms preprocess, 726.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 13 cars, 1 traffic light, 1 backpack, 727.3ms\n",
      "Speed: 0.0ms preprocess, 727.3ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 12 cars, 1 traffic light, 1 backpack, 1 handbag, 710.0ms\n",
      "Speed: 8.0ms preprocess, 710.0ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 11 cars, 1 traffic light, 1 backpack, 728.5ms\n",
      "Speed: 8.0ms preprocess, 728.5ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 10 cars, 1 traffic light, 1 backpack, 696.6ms\n",
      "Speed: 3.5ms preprocess, 696.6ms inference, 15.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 10 cars, 1 traffic light, 1 backpack, 704.8ms\n",
      "Speed: 1.1ms preprocess, 704.8ms inference, 4.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 11 cars, 1 motorcycle, 1 traffic light, 1 backpack, 696.7ms\n",
      "Speed: 1.2ms preprocess, 696.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 10 cars, 1 traffic light, 1 backpack, 711.2ms\n",
      "Speed: 1.7ms preprocess, 711.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 10 cars, 1 traffic light, 1 backpack, 696.3ms\n",
      "Speed: 1.4ms preprocess, 696.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 10 cars, 1 traffic light, 1 backpack, 719.0ms\n",
      "Speed: 0.0ms preprocess, 719.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 9 cars, 1 traffic light, 1 backpack, 696.9ms\n",
      "Speed: 9.2ms preprocess, 696.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 8 cars, 1 motorcycle, 1 traffic light, 1 backpack, 698.8ms\n",
      "Speed: 9.6ms preprocess, 698.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 710.5ms\n",
      "Speed: 0.0ms preprocess, 710.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 6 cars, 1 traffic light, 1 backpack, 1 handbag, 706.1ms\n",
      "Speed: 0.0ms preprocess, 706.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 8 cars, 1 motorcycle, 1 traffic light, 1 backpack, 1 handbag, 711.7ms\n",
      "Speed: 0.0ms preprocess, 711.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 1 handbag, 720.8ms\n",
      "Speed: 0.0ms preprocess, 720.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 1 handbag, 704.2ms\n",
      "Speed: 9.3ms preprocess, 704.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 6 cars, 1 traffic light, 1 backpack, 701.2ms\n",
      "Speed: 3.2ms preprocess, 701.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 2 handbags, 710.9ms\n",
      "Speed: 1.6ms preprocess, 710.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 5 cars, 1 traffic light, 1 backpack, 2 handbags, 706.2ms\n",
      "Speed: 0.0ms preprocess, 706.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 1 skateboard, 706.7ms\n",
      "Speed: 1.7ms preprocess, 706.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 1 handbag, 703.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 7.3ms preprocess, 703.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 8 cars, 1 traffic light, 1 backpack, 1 handbag, 718.4ms\n",
      "Speed: 0.0ms preprocess, 718.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 9 cars, 1 traffic light, 1 backpack, 1 handbag, 705.9ms\n",
      "Speed: 0.0ms preprocess, 705.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 8 cars, 1 traffic light, 1 backpack, 710.0ms\n",
      "Speed: 1.9ms preprocess, 710.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 6 cars, 1 motorcycle, 1 traffic light, 1 backpack, 717.8ms\n",
      "Speed: 0.0ms preprocess, 717.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 6 cars, 1 motorcycle, 2 backpacks, 1 handbag, 713.3ms\n",
      "Speed: 0.0ms preprocess, 713.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 7 cars, 1 motorcycle, 2 backpacks, 1 handbag, 710.7ms\n",
      "Speed: 8.0ms preprocess, 710.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 7 cars, 2 backpacks, 1 skateboard, 707.2ms\n",
      "Speed: 0.0ms preprocess, 707.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 7 cars, 3 backpacks, 1 handbag, 728.3ms\n",
      "Speed: 0.0ms preprocess, 728.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 12 cars, 2 backpacks, 719.1ms\n",
      "Speed: 0.0ms preprocess, 719.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 10 cars, 2 backpacks, 705.1ms\n",
      "Speed: 0.0ms preprocess, 705.1ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 10 cars, 1 backpack, 1 handbag, 717.2ms\n",
      "Speed: 0.0ms preprocess, 717.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 10 cars, 1 backpack, 1 handbag, 706.8ms\n",
      "Speed: 0.0ms preprocess, 706.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 11 cars, 2 backpacks, 706.7ms\n",
      "Speed: 0.0ms preprocess, 706.7ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 11 cars, 1 backpack, 705.1ms\n",
      "Speed: 1.3ms preprocess, 705.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 12 cars, 1 backpack, 704.1ms\n",
      "Speed: 8.1ms preprocess, 704.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 10 cars, 1 traffic light, 2 backpacks, 711.5ms\n",
      "Speed: 8.5ms preprocess, 711.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 11 cars, 1 traffic light, 2 backpacks, 713.0ms\n",
      "Speed: 0.0ms preprocess, 713.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 13 cars, 1 traffic light, 1 backpack, 725.7ms\n",
      "Speed: 8.0ms preprocess, 725.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 13 cars, 1 traffic light, 1 bird, 723.2ms\n",
      "Speed: 1.3ms preprocess, 723.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 14 cars, 1 traffic light, 1 bird, 726.1ms\n",
      "Speed: 4.2ms preprocess, 726.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 12 cars, 1 traffic light, 1 bird, 707.1ms\n",
      "Speed: 8.0ms preprocess, 707.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 11 cars, 1 traffic light, 1 handbag, 738.7ms\n",
      "Speed: 3.1ms preprocess, 738.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 12 cars, 1 traffic light, 1 bench, 1 handbag, 1 suitcase, 719.7ms\n",
      "Speed: 5.0ms preprocess, 719.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 9 cars, 1 traffic light, 1 bench, 1 backpack, 2 handbags, 720.8ms\n",
      "Speed: 0.0ms preprocess, 720.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 8 cars, 1 traffic light, 1 backpack, 2 handbags, 715.6ms\n",
      "Speed: 4.1ms preprocess, 715.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 10 cars, 1 traffic light, 2 handbags, 712.1ms\n",
      "Speed: 0.0ms preprocess, 712.1ms inference, 15.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 9 cars, 1 traffic light, 1 handbag, 722.2ms\n",
      "Speed: 8.5ms preprocess, 722.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 1 handbag, 711.6ms\n",
      "Speed: 7.7ms preprocess, 711.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 7 cars, 1 traffic light, 1 handbag, 699.0ms\n",
      "Speed: 1.5ms preprocess, 699.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 7 cars, 1 traffic light, 1 backpack, 1 handbag, 717.2ms\n",
      "Speed: 0.0ms preprocess, 717.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 6 cars, 1 backpack, 1 handbag, 715.6ms\n",
      "Speed: 9.5ms preprocess, 715.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 6 cars, 1 backpack, 2 handbags, 713.0ms\n",
      "Speed: 6.6ms preprocess, 713.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 5 cars, 1 backpack, 1 handbag, 720.5ms\n",
      "Speed: 4.3ms preprocess, 720.5ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 7 cars, 1 backpack, 2 handbags, 1 suitcase, 699.0ms\n",
      "Speed: 3.8ms preprocess, 699.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 7 cars, 1 backpack, 2 handbags, 722.5ms\n",
      "Speed: 0.0ms preprocess, 722.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 7 cars, 2 backpacks, 1 handbag, 1 suitcase, 715.7ms\n",
      "Speed: 0.0ms preprocess, 715.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 8 cars, 1 traffic light, 2 backpacks, 2 handbags, 721.1ms\n",
      "Speed: 0.5ms preprocess, 721.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 9 cars, 1 traffic light, 2 backpacks, 1 handbag, 704.1ms\n",
      "Speed: 8.1ms preprocess, 704.1ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 10 cars, 1 traffic light, 2 backpacks, 1 handbag, 715.2ms\n",
      "Speed: 0.0ms preprocess, 715.2ms inference, 4.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 7 cars, 1 traffic light, 2 backpacks, 2 handbags, 725.1ms\n",
      "Speed: 0.0ms preprocess, 725.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 8 cars, 1 traffic light, 2 backpacks, 2 handbags, 711.3ms\n",
      "Speed: 0.0ms preprocess, 711.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 6 cars, 1 traffic light, 1 backpack, 2 handbags, 713.1ms\n",
      "Speed: 8.0ms preprocess, 713.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 2 handbags, 712.1ms\n",
      "Speed: 0.0ms preprocess, 712.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 2 handbags, 715.5ms\n",
      "Speed: 2.1ms preprocess, 715.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 6 cars, 1 traffic light, 1 backpack, 3 handbags, 716.7ms\n",
      "Speed: 2.2ms preprocess, 716.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 11 cars, 1 traffic light, 1 backpack, 2 handbags, 723.4ms\n",
      "Speed: 0.0ms preprocess, 723.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 8 cars, 1 traffic light, 1 backpack, 2 handbags, 711.0ms\n",
      "Speed: 0.0ms preprocess, 711.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 10 cars, 1 traffic light, 1 backpack, 1 handbag, 718.3ms\n",
      "Speed: 0.0ms preprocess, 718.3ms inference, 6.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 9 cars, 1 traffic light, 1 handbag, 722.1ms\n",
      "Speed: 0.0ms preprocess, 722.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 8 cars, 1 traffic light, 1 handbag, 714.1ms\n",
      "Speed: 0.0ms preprocess, 714.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 6 cars, 1 traffic light, 717.9ms\n",
      "Speed: 0.0ms preprocess, 717.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 6 cars, 1 traffic light, 716.7ms\n",
      "Speed: 6.5ms preprocess, 716.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 7 cars, 1 traffic light, 1 handbag, 725.8ms\n",
      "Speed: 0.0ms preprocess, 725.8ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 8 cars, 1 traffic light, 698.1ms\n",
      "Speed: 1.6ms preprocess, 698.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 7 cars, 1 traffic light, 720.2ms\n",
      "Speed: 7.0ms preprocess, 720.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 8 cars, 1 traffic light, 709.3ms\n",
      "Speed: 8.3ms preprocess, 709.3ms inference, 3.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 7 cars, 1 traffic light, 718.8ms\n",
      "Speed: 5.7ms preprocess, 718.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 7 cars, 1 traffic light, 707.8ms\n",
      "Speed: 0.0ms preprocess, 707.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 8 cars, 1 traffic light, 721.9ms\n",
      "Speed: 7.0ms preprocess, 721.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 7 cars, 1 traffic light, 1 handbag, 717.7ms\n",
      "Speed: 0.0ms preprocess, 717.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 7 cars, 1 traffic light, 1 handbag, 719.4ms\n",
      "Speed: 0.0ms preprocess, 719.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 6 cars, 1 traffic light, 1 handbag, 732.4ms\n",
      "Speed: 0.0ms preprocess, 732.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 9 cars, 1 motorcycle, 1 traffic light, 1 handbag, 734.2ms\n",
      "Speed: 1.6ms preprocess, 734.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 7 cars, 1 motorcycle, 1 traffic light, 737.9ms\n",
      "Speed: 1.2ms preprocess, 737.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 6 cars, 744.0ms\n",
      "Speed: 8.1ms preprocess, 744.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 7 cars, 1 backpack, 1 handbag, 711.8ms\n",
      "Speed: 3.3ms preprocess, 711.8ms inference, 14.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 5 cars, 1 handbag, 714.8ms\n",
      "Speed: 0.0ms preprocess, 714.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 5 cars, 2 handbags, 706.4ms\n",
      "Speed: 0.0ms preprocess, 706.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 6 cars, 728.0ms\n",
      "Speed: 0.0ms preprocess, 728.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 7 cars, 1 traffic light, 717.6ms\n",
      "Speed: 0.0ms preprocess, 717.6ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 6 cars, 1 backpack, 3 handbags, 720.8ms\n",
      "Speed: 10.3ms preprocess, 720.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 8 cars, 1 motorcycle, 1 handbag, 725.8ms\n",
      "Speed: 0.0ms preprocess, 725.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 7 cars, 1 traffic light, 2 handbags, 716.9ms\n",
      "Speed: 0.0ms preprocess, 716.9ms inference, 17.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 9 cars, 1 motorcycle, 1 traffic light, 2 handbags, 712.5ms\n",
      "Speed: 0.0ms preprocess, 712.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 10 cars, 1 motorcycle, 1 traffic light, 2 handbags, 725.0ms\n",
      "Speed: 9.1ms preprocess, 725.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 9 cars, 1 motorcycle, 1 traffic light, 1 handbag, 723.6ms\n",
      "Speed: 3.9ms preprocess, 723.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 9 cars, 1 motorcycle, 1 traffic light, 2 backpacks, 713.9ms\n",
      "Speed: 0.0ms preprocess, 713.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 8 cars, 1 traffic light, 3 handbags, 718.6ms\n",
      "Speed: 0.0ms preprocess, 718.6ms inference, 7.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 8 cars, 1 traffic light, 1 handbag, 722.0ms\n",
      "Speed: 0.0ms preprocess, 722.0ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 9 cars, 1 traffic light, 3 handbags, 716.2ms\n",
      "Speed: 8.0ms preprocess, 716.2ms inference, 4.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 6 cars, 1 traffic light, 2 handbags, 722.0ms\n",
      "Speed: 0.0ms preprocess, 722.0ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 7 cars, 1 traffic light, 1 handbag, 709.6ms\n",
      "Speed: 0.0ms preprocess, 709.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 9 cars, 1 traffic light, 1 handbag, 729.6ms\n",
      "Speed: 0.0ms preprocess, 729.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 12 cars, 1 traffic light, 710.3ms\n",
      "Speed: 0.0ms preprocess, 710.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 11 cars, 1 traffic light, 1 handbag, 698.2ms\n",
      "Speed: 1.5ms preprocess, 698.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 10 cars, 1 traffic light, 1 handbag, 722.2ms\n",
      "Speed: 0.0ms preprocess, 722.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 10 cars, 1 traffic light, 2 handbags, 742.7ms\n",
      "Speed: 0.0ms preprocess, 742.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 10 cars, 1 traffic light, 727.7ms\n",
      "Speed: 5.5ms preprocess, 727.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 10 cars, 1 traffic light, 1 handbag, 707.3ms\n",
      "Speed: 6.0ms preprocess, 707.3ms inference, 5.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 8 cars, 1 traffic light, 1 handbag, 712.8ms\n",
      "Speed: 0.0ms preprocess, 712.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 9 cars, 1 traffic light, 715.8ms\n",
      "Speed: 2.7ms preprocess, 715.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 7 cars, 1 traffic light, 717.0ms\n",
      "Speed: 3.5ms preprocess, 717.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 7 cars, 1 traffic light, 1 backpack, 1 handbag, 713.0ms\n",
      "Speed: 8.1ms preprocess, 713.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 12 cars, 1 traffic light, 1 backpack, 1 handbag, 704.4ms\n",
      "Speed: 0.0ms preprocess, 704.4ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 13 cars, 1 traffic light, 1 handbag, 708.0ms\n",
      "Speed: 8.1ms preprocess, 708.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 10 persons, 12 cars, 1 traffic light, 1 umbrella, 1 handbag, 699.1ms\n",
      "Speed: 0.0ms preprocess, 699.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 12 cars, 1 traffic light, 1 umbrella, 1 handbag, 712.2ms\n",
      "Speed: 0.0ms preprocess, 712.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 14 cars, 1 traffic light, 718.4ms\n",
      "Speed: 0.0ms preprocess, 718.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 11 cars, 1 motorcycle, 1 traffic light, 1 handbag, 704.1ms\n",
      "Speed: 0.0ms preprocess, 704.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 12 cars, 1 traffic light, 1 handbag, 698.3ms\n",
      "Speed: 1.9ms preprocess, 698.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 12 cars, 1 traffic light, 1 handbag, 1 skateboard, 707.4ms\n",
      "Speed: 0.0ms preprocess, 707.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 8 cars, 1 traffic light, 1 handbag, 706.2ms\n",
      "Speed: 7.1ms preprocess, 706.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 9 cars, 1 traffic light, 1 handbag, 1 suitcase, 1 skateboard, 709.7ms\n",
      "Speed: 0.0ms preprocess, 709.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 8 cars, 1 traffic light, 3 handbags, 714.1ms\n",
      "Speed: 0.0ms preprocess, 714.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 9 cars, 1 traffic light, 3 handbags, 1 skateboard, 706.3ms\n",
      "Speed: 11.5ms preprocess, 706.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 9 cars, 1 traffic light, 3 handbags, 1 skateboard, 709.2ms\n",
      "Speed: 1.0ms preprocess, 709.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 10 cars, 1 traffic light, 2 handbags, 3 skateboards, 710.8ms\n",
      "Speed: 1.2ms preprocess, 710.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 9 cars, 1 traffic light, 2 handbags, 709.5ms\n",
      "Speed: 9.5ms preprocess, 709.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 9 cars, 1 traffic light, 3 handbags, 2 skateboards, 716.9ms\n",
      "Speed: 0.0ms preprocess, 716.9ms inference, 1.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 10 cars, 1 traffic light, 3 handbags, 1 skateboard, 722.7ms\n",
      "Speed: 0.0ms preprocess, 722.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 9 cars, 1 traffic light, 2 handbags, 733.5ms\n",
      "Speed: 0.0ms preprocess, 733.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 9 cars, 1 traffic light, 2 handbags, 741.5ms\n",
      "Speed: 0.0ms preprocess, 741.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 8 cars, 1 traffic light, 2 handbags, 1 skateboard, 737.2ms\n",
      "Speed: 1.1ms preprocess, 737.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 8 cars, 1 traffic light, 3 handbags, 736.2ms\n",
      "Speed: 2.7ms preprocess, 736.2ms inference, 6.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 8 cars, 1 traffic light, 3 handbags, 1 skateboard, 734.2ms\n",
      "Speed: 0.0ms preprocess, 734.2ms inference, 7.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 8 cars, 1 traffic light, 1 handbag, 720.5ms\n",
      "Speed: 1.1ms preprocess, 720.5ms inference, 4.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 7 cars, 1 traffic light, 1 skateboard, 716.1ms\n",
      "Speed: 0.0ms preprocess, 716.1ms inference, 6.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 7 cars, 1 traffic light, 2 handbags, 735.4ms\n",
      "Speed: 4.5ms preprocess, 735.4ms inference, 15.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 9 cars, 1 traffic light, 728.5ms\n",
      "Speed: 3.4ms preprocess, 728.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 9 cars, 1 traffic light, 725.9ms\n",
      "Speed: 0.0ms preprocess, 725.9ms inference, 2.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 9 cars, 1 traffic light, 1 handbag, 730.8ms\n",
      "Speed: 2.4ms preprocess, 730.8ms inference, 1.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 9 cars, 1 traffic light, 1 handbag, 732.7ms\n",
      "Speed: 0.0ms preprocess, 732.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 8 cars, 1 traffic light, 727.9ms\n",
      "Speed: 5.2ms preprocess, 727.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 9 cars, 1 traffic light, 1 handbag, 714.5ms\n",
      "Speed: 4.9ms preprocess, 714.5ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 9 cars, 1 traffic light, 1 handbag, 709.7ms\n",
      "Speed: 1.1ms preprocess, 709.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 10 cars, 1 traffic light, 2 benchs, 1 handbag, 719.4ms\n",
      "Speed: 0.0ms preprocess, 719.4ms inference, 6.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 8 cars, 1 traffic light, 1 bench, 1 handbag, 705.1ms\n",
      "Speed: 7.0ms preprocess, 705.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 8 persons, 8 cars, 1 traffic light, 1 bench, 1 handbag, 728.1ms\n",
      "Speed: 0.0ms preprocess, 728.1ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 9 cars, 1 traffic light, 1 bench, 2 handbags, 729.7ms\n",
      "Speed: 0.0ms preprocess, 729.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 7 persons, 10 cars, 1 traffic light, 1 bench, 2 handbags, 707.3ms\n",
      "Speed: 4.7ms preprocess, 707.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 10 cars, 1 traffic light, 2 handbags, 725.1ms\n",
      "Speed: 0.0ms preprocess, 725.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 9 cars, 1 traffic light, 2 handbags, 708.9ms\n",
      "Speed: 7.2ms preprocess, 708.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 12 cars, 1 traffic light, 3 handbags, 724.7ms\n",
      "Speed: 0.0ms preprocess, 724.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 10 cars, 1 traffic light, 2 handbags, 1 skateboard, 735.5ms\n",
      "Speed: 8.0ms preprocess, 735.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 9 cars, 1 traffic light, 1 bench, 3 handbags, 720.6ms\n",
      "Speed: 0.0ms preprocess, 720.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 4 persons, 9 cars, 1 traffic light, 1 bench, 3 handbags, 710.8ms\n",
      "Speed: 0.0ms preprocess, 710.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 8 cars, 1 traffic light, 1 bench, 3 handbags, 1 skateboard, 702.4ms\n",
      "Speed: 7.0ms preprocess, 702.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 5 persons, 8 cars, 1 traffic light, 1 bench, 2 handbags, 711.6ms\n",
      "Speed: 4.4ms preprocess, 711.6ms inference, 13.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 8 cars, 1 traffic light, 2 benchs, 2 handbags, 696.4ms\n",
      "Speed: 4.6ms preprocess, 696.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "0: 224x640 6 persons, 7 cars, 1 traffic light, 2 benchs, 3 handbags, 706.5ms\n",
      "Speed: 0.0ms preprocess, 706.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 640)\n"
     ]
    }
   ],
   "source": [
    "# options for videos: \n",
    "# vehicles moving vertically  (vertical: True): los_angeles.mp4, highway.mp4\n",
    "# vehicles moving horzintally (vertical: False): driving1.mp4\n",
    "#countVehicles('los_angeles.mp4', 'test2.mp4', True)\n",
    "countVehicles('driving1.mp4', 'test2.mp4', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335e701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_tracking_new",
   "language": "python",
   "name": "object_tracking_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
